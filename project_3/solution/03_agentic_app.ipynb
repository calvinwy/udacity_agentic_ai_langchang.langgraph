{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d80ddd8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "68aa44df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from utils import chat_interface\n",
    "import os\n",
    "import math\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from typing import Dict, Any, List, Annotated, Literal, Tuple\n",
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074877bd",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "837f6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_retrieval = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f6da4d",
   "metadata": {},
   "source": [
    "### Setup LLMs for different Technical Support Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# llm_base_url = \"https://openai.vocareum.com/v1\"\n",
    "llm_base_url = \"https://api.openai.com/v1\"\n",
    "\n",
    "\n",
    "llm_low = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.0,\n",
    "    base_url=llm_base_url,\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "llm_medium = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    "    base_url=llm_base_url,\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "llm_high = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.0,\n",
    "    base_url=llm_base_url,\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "embeddings_fn = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    base_url=llm_base_url,\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac44299",
   "metadata": {},
   "source": [
    "### Create Vector Database Connection for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "302b9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromadb_directory = \"vectorstore\"\n",
    "collection_name = \"knowledge_vecotr_store\"\n",
    "vector_store = Chroma(\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embeddings_fn,\n",
    "    persist_directory=chromadb_directory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa125de1",
   "metadata": {},
   "source": [
    "## Agent State Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb6e5de",
   "metadata": {},
   "source": [
    "State Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6348a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicketState(MessagesState):\n",
    "    \"\"\"State for the IT ticket workflow.\"\"\"\n",
    "    query: HumanMessage\n",
    "    # retrieved documents\n",
    "    documents: List[Document]\n",
    "    # routing signals\n",
    "    priority: Literal['normal', 'urgent', 'vip'] = 'normal'\n",
    "    intent: Literal['how_to', 'troubleshooting_basic', 'status_check',\n",
    "                    'security', 'refund_high', 'outage', 'others'] = 'others'\n",
    "    retrieval_score: float = 0.0\n",
    "    answer_confidence: float = 0.0\n",
    "    sentiment: float = 0.0\n",
    "    # control/status\n",
    "    assigned_group: Literal['L1', 'L2', 'L3', 'human'] = 'L1'\n",
    "    eval_status: Literal['resolved', 'needs_clarification', 'escalate'] = 'needs_clarification'\n",
    "    turns_at_level: int = 0\n",
    "    escalation_reason: Optional[Literal['low_confidence',\n",
    "                                        'high_impact_or_sensitive',\n",
    "                                        'unresolved_or_negative',\n",
    "                                        'sla_breach']] = None\n",
    "    # SLA/aging\n",
    "    level_entered_at: datetime = datetime.utcnow()\n",
    "    sla_minutes: int = 3  # example per level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e4584",
   "metadata": {},
   "source": [
    "Standardized Output for Subagent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bf7e2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentOutput(BaseModel):\n",
    "    \"\"\"Standardized output to ensure it is from the possible values\"\"\"\n",
    "    intent: Annotated[Literal['how_to','troubleshooting_basic','status_check','security','refund_high','outage','others'], \n",
    "                      Field(description=\"The intent of the IT ticket\")]\n",
    "    \n",
    "class SentimentOutput(BaseModel):\n",
    "    \"\"\"Standardized output to ensure it is from the possible values\"\"\"\n",
    "    sentiment: Annotated[float, Field(description=\"The user's sentiment\",\n",
    "                                      ge=-1.0,\n",
    "                                      le=1.0)]\n",
    "\n",
    "class ConfidenceOutput(BaseModel):\n",
    "    \"\"\"Standardized output to ensure it is from the possible values\"\"\"\n",
    "    confidencet: Annotated[float, Field(description=\"The confidence of answer toward the query\",\n",
    "                                      ge=0.0,\n",
    "                                      le=1.0)]\n",
    "\n",
    "# ChromaDB Similarity Search Output Structure        \n",
    "class VectorDocument(BaseModel):\n",
    "    \"\"\"The contents of a retrieved LangChain Document.\"\"\"\n",
    "    id: int\n",
    "    page_content: str\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "class SearchResultItem(BaseModel):\n",
    "    \"\"\"Represents the tuple (Document, score) as a JSON object.\"\"\"\n",
    "    document: VectorDocument = Field(description=\"The document content and metadata.\")\n",
    "    score: float = Field(description=\"The L2 distance.\")\n",
    "\n",
    "class QueryAttributeOutput(BaseModel):\n",
    "    \"\"\"Standardized output to ensure it is from the possible values\"\"\"\n",
    "    intent: Annotated[Literal['how_to','troubleshooting_basic','status_check','security','refund_high','outage','others'], \n",
    "                      Field(description=\"The intent of the IT ticket\")]\n",
    "    sentiment: Annotated[float, Field(description=\"The user's sentiment\",\n",
    "                                      ge=-1.0,\n",
    "                                      le=1.0)]\n",
    "    confidence: Annotated[float, Field(description=\"The confidence of answer toward the query\",\n",
    "                                      ge=0.0,\n",
    "                                      le=1.0)]\n",
    "    retrival: Annotated[List[SearchResultItem], Field(description=\"List of retrieved document and score pairs.\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b18650b",
   "metadata": {},
   "source": [
    "# Agent Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6e889a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def knowledge_retrival(query: str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Evaluate whether the knowledge base has enough content to address the query and return the relevant content indices.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query string\n",
    "    \n",
    "    Returns:\n",
    "        retrival (List[tuple[Document,float]]): Response from the ChromaDB database for the retrieved documents and the corresponding\n",
    "                                                distance measure.\n",
    "    \"\"\"\n",
    "    results = vector_store.similarity_search_with_score(\n",
    "        query=query,\n",
    "        k=num_retrieval,\n",
    "    )\n",
    "\n",
    "    # Convert the output to recognizable types for Pydantic to work\n",
    "    retrival = []\n",
    "    for doc, score in results:\n",
    "        retrival.append({\n",
    "            \"document\": {\n",
    "                \"id\": int(doc.id),\n",
    "                \"page_content\": doc.page_content,\n",
    "                \"metadata\": doc.metadata\n",
    "            },\n",
    "            \"score\": score\n",
    "        })\n",
    "    return retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66f08124",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def intent_check(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Evaluate the intent of the query for routing decision.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query string\n",
    "    \n",
    "    Returns:\n",
    "        intent (str): One of ['how_to', 'troubleshooting_basic', 'status_check',\n",
    "                              'security', 'refund_high', 'outage', 'others']\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "        You are an expert evaluating the intent of IT ticket submitted by users and you are suppose to\n",
    "        classify it as one of the following intent: ['how_to', 'troubleshooting_basic', 'status_check',\n",
    "        'security', 'refund_high', 'outage', 'others'].\n",
    "\n",
    "        Output a single one of the above intent in the list, do not provide any explanation or description\n",
    "        to your answer.\n",
    "\n",
    "        Here is the user query:\n",
    "        {query}\n",
    "        \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template = prompt_template,\n",
    "        input_variables = [\"query\"],\n",
    "        ).invoke({\"query\": query})\n",
    "    response = llm_medium.with_structured_output(IntentOutput).invoke(prompt)\n",
    "    intent = response.intent\n",
    "    return intent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3551a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def sentiment_analyzer(query: str) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the sentiment of the input query and output a score between -1 to 1.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query string\n",
    "    \n",
    "    Returns:\n",
    "        sentiment (float): Score between -1 to 1, where -1 is upset/angry/negative where 1 is happy/optimisitic/positive\n",
    "    \"\"\"\n",
    "    prompt_template = \"\"\"\n",
    "        You are an expert in marketing and assessing the sentiment of the customer.  You need to provide a score between\n",
    "        -1 to 1 where -1 is upset/angry/negative where 1 is happy/optimisitic/positive.\n",
    "\n",
    "        Output a single number, do not provide any explanation or description to your answer.\n",
    "\n",
    "        Here is the user query:\n",
    "        {query}\n",
    "        \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template = prompt_template,\n",
    "        input_variables = [\"query\"],\n",
    "        ).invoke({\"query\": query})\n",
    "    response = llm_medium.with_structured_output(SentimentOutput).invoke(prompt)\n",
    "    sentiment = response.sentiment\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "302413ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def confidence_evaluator(query: str, answer: str) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the confidence of the answer towards answering the query by providing a score between 0 to 1.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query string\n",
    "        answer (str): The answer provided by the IT support\n",
    "    \n",
    "    Returns:\n",
    "        confidence (float): Score between 0 to 1, where 0 corresponse to an answer where it is completely irrelevant to\n",
    "        the querey, where 1 is spot on and it solves the user's query.\n",
    "    \"\"\"\n",
    "    prompt_template = \"\"\"\n",
    "        You are an expert in quality control to evaluate whether the support team had been doing a good job for providing\n",
    "        the relevant response to the user.  You need to provide a score between 0 to 1, where 0 corresponse to an answer \n",
    "        where it is completely irrelevant to the querey, where 1 is spot on and it solves the user's query.\n",
    "\n",
    "        Here is the user query:\n",
    "        {query}\n",
    "\n",
    "        Here is the support team's response:\n",
    "        {answer}\n",
    "        \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template = prompt_template,\n",
    "        input_variables = [\"query\",\"answer\"],\n",
    "        ).invoke({\"query\": query, \"answer\": answer})\n",
    "    response = llm_medium.with_structured_output(ConfidenceOutput).invoke(prompt)\n",
    "    confidence = response.confidence\n",
    "    return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8674d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_initial_evaluator = llm_medium.bind_tools([knowledge_retrival,intent_check,sentiment_analyzer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4281a8d",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_TOPICS = {\"how_to\",\"troubleshooting_basic\",\"status_check\"}\n",
    "L2_TOPICS = {\"others\",\"refund_high\"}\n",
    "L3_TOPICS = {\"outage\",\"security\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ed468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_assessment_agent(state: TicketState):\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    # Evaluate Retrival Score, Intent, Sentiment of the Query\n",
    "    prompt_template = \"\"\"\n",
    "        You are a IT ticket evaluation agent, given the user query:\n",
    "        {query}\n",
    "\n",
    "        Use the following tools to provide insights for the user query:\n",
    "            (1) Use `intent_check` to identify the \"intent\" attribute of the given query\n",
    "            (2) Use `sentiment_analyzer` to estimate the \"sentiment\" of the given query\n",
    "            (3) Use `knowledge_retrival` to extract \"retrival\" attribute from the ChromaDB knowledge database\n",
    "        \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template = prompt_template,\n",
    "        input_variables = [\"query\"],\n",
    "        ).invoke({\"query\": query})\n",
    "\n",
    "    response = llm_medium.with_structured_output(QueryAttributeOutput).invoke(prompt)\n",
    "\n",
    "    llm_initial_evaluator.invoke\n",
    "    similarity = [ 1-(result[1]/math.sqrt(2)) for result in results ]  # ChromaDB uses L2 distance, it requires to perform this operation to convert to similarity\n",
    "    max_score = max(similarity)\n",
    "    retrival_score = max_score\n",
    "\n",
    "    indices = [ int(result[0].id) for result in results ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858fc49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Develop your agents under `agentic/agents`\n",
    "# TODO: Develop your tools under `agentic/tools`\n",
    "# TODO: Modify `agentic/workflow` in order to orchestrate your agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEALLY YOUR ONLY IMPORT HERE IS:\n",
    "# from agentic.workflow import orchestrator\n",
    "\n",
    "from agentic.workflow import orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_interface(orchestrator, \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe200f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(orchestrator.get_state_history(\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"1\",\n",
    "        }\n",
    "    }\n",
    "))[0].values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e9f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be7ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f3de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39006a38",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e609113",
   "metadata": {},
   "source": [
    "# Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1a8c7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hi, I have a question regarding the billing for the events I attended last month. There seems to be a discrepancy in the charges, and I would like to understand the breakdown of the costs. Could you please provide a detailed billing statement? Thank you.\"\n",
    "results = vector_store.similarity_search_with_score(\n",
    "    query=query,\n",
    "    k=num_retrieval,\n",
    ")\n",
    "# similarity = [ 1-(result[1]/math.sqrt(2)) for result in results ]\n",
    "# indices = [ int(result[0].id) for result in results ]\n",
    "\n",
    "retrival = []\n",
    "for doc, score in results:\n",
    "    retrival.append({\n",
    "        \"document\": {\n",
    "            \"id\": int(doc.id),\n",
    "            \"page_content\": doc.page_content,\n",
    "            \"metadata\": doc.metadata\n",
    "        },\n",
    "        \"score\": score\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0766e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDocument(BaseModel):\n",
    "    \"\"\"The contents of a retrieved LangChain Document.\"\"\"\n",
    "    id: int\n",
    "    page_content: str\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "class SearchResultItem(BaseModel):\n",
    "    \"\"\"Represents the tuple (Document, score) as a JSON object.\"\"\"\n",
    "    document: VectorDocument = Field(description=\"The document content and metadata.\")\n",
    "    score: float = Field(description=\"The L2 distance.\")\n",
    "\n",
    "class QueryAttributeOutput(BaseModel):\n",
    "    retrival: Annotated[List[SearchResultItem], Field(description=\"List of retrieved document and score pairs.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bdabab55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryAttributeOutput(retrival=[SearchResultItem(document=VectorDocument(id=19, page_content='How to Handle Billing Discrepancies: For billing issues:\\n\\n- Review your billing history in the CultPass app\\n- Contact support if discrepancies are found\\n- Provide transaction details for faster resolution\\n\\n**Suggested phrasing:**\\n\"If you notice any billing discrepancies, review your history and contact support with transaction details.\"', metadata={'tags': 'billing, escalation, support'}), score=1.0406265258789062), SearchResultItem(document=VectorDocument(id=5, page_content='Understanding CultPass Pricing: CultPass offers flexible pricing options:\\n\\n- Monthly subscription: Access to 4 experiences per month\\n- Annual subscription: Discounted rate for a year-long access\\n- Additional fees may apply for premium events\\n\\n**Suggested phrasing:**\\n\"Explore our flexible pricing plans, including monthly and annual subscriptions. Note that some premium events may incur additional fees.\"', metadata={'tags': 'pricing, subscription, benefits'}), score=1.2658634185791016), SearchResultItem(document=VectorDocument(id=14, page_content='Handling Event Overbooking: In case of overbooking:\\n\\n- Notify affected users via email\\n- Offer alternative dates or events\\n- Provide a refund if no alternatives are suitable\\n\\n**Suggested phrasing:**\\n\"We apologize for any inconvenience due to overbooking. Please check your email for alternative options or refund details.\"', metadata={'tags': 'events, booking, cancelation'}), score=1.321397066116333), SearchResultItem(document=VectorDocument(id=11, page_content='How to Access Premium Events: Accessing premium events requires:\\n\\n- A valid CultPass subscription\\n- Payment of any additional fees\\n- Booking through the CultPass app\\n\\n**Suggested phrasing:**\\n\"Access premium events by ensuring your subscription is active and any additional fees are paid. Book through the app.\"', metadata={'tags': 'access, events, booking'}), score=1.3554763793945312), SearchResultItem(document=VectorDocument(id=1, page_content='What\\'s Included in a CultPass Subscription: Each user is entitled to 4 cultural experiences per month, which may include:\\n- Art exhibitions\\n- Museum entries\\n- Music concerts\\n- Film screenings and more\\n\\nSome premium experiences may require an additional fee (visible in the app).\\n\\n**Suggested phrasing:**\\n\"Your CultPass subscription includes 4 curated experiences each month. You can choose from museums, concerts, film events and more. Premium events may have an extra cost, which is shown during reservation.\"', metadata={'tags': 'subscription, benefits, pricing, access'}), score=1.406754970550537)])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QueryAttributeOutput(retrival=retrival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a5f4af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Hi, I have a question regarding the billing for the events I attended last month. There seems to be a discrepancy in the charges, and I would like to understand the breakdown of the costs. Could you please provide a detailed billing statement? Thank you.\"\n",
    "prompt_template = \"\"\"\n",
    "    You are an expert evaluating the intent of IT ticket submitted by users and you are suppose to\n",
    "    classify it as one of the following intent: ['how_to', 'troubleshooting_basic', 'status_check',\n",
    "    'security', 'refund_high', 'outage', 'others'].\n",
    "\n",
    "    Output a single one of the above intent in the list, do not provide any explanation or description\n",
    "    to your answer.\n",
    "\n",
    "    Here is the user query:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template = prompt_template,\n",
    "    input_variables = [\"query\"],\n",
    "    ).invoke({\"query\": query})\n",
    "response = llm_medium.with_structured_output(IntentOutput).invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5eba1a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Hi, I have a question regarding the billing for the events I attended last month. There seems to be a discrepancy in the charges, and I would like to understand the breakdown of the costs. Could you please provide a detailed billing statement? Thank you.\"\n",
    "query = \"You are so useless!\"\n",
    "prompt_template = \"\"\"\n",
    "    You are an expert in marketing and assessing the sentiment of the customer.  You need to provide a score between\n",
    "    -1 to 1 where -1 is upset/angry/negative where 1 is happy/optimisitic/positive.\n",
    "\n",
    "    Output a single number, do not provide any explanation or description to your answer.\n",
    "\n",
    "    Here is the user query:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template = prompt_template,\n",
    "    input_variables = [\"query\"],\n",
    "    ).invoke({\"query\": query})\n",
    "response = llm_medium.with_structured_output(SentimentOutput).invoke(prompt)\n",
    "sentiment = response.sentiment\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a4410d29",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'QueryAttributeOutput': In context=('properties', 'document', 'properties', 'metadata'), 'additionalProperties' is required to be supplied and to be false.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[156]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      4\u001b[39m prompt_template = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33m    You are a IT ticket evaluation agent, given the user query:\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m    \u001b[39m\u001b[38;5;132;01m{query}\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[33m    Use `knowledge_retrival` to extract \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mretrival\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m attribute from the ChromaDB knowledge database\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     10\u001b[39m prompt = PromptTemplate(\n\u001b[32m     11\u001b[39m     template = prompt_template,\n\u001b[32m     12\u001b[39m     input_variables = [\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     13\u001b[39m     ).invoke({\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m: query})\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m response = \u001b[43mllm_initial_evaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQueryAttributeOutput\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/langchain_core/runnables/base.py:3141\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3139\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3140\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3141\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3142\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3143\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/langchain_core/runnables/base.py:5548\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5541\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5543\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5546\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5547\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5549\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5550\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5551\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1356\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1355\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1358\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1359\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1360\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1361\u001b[39m ):\n\u001b[32m   1362\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1330\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1328\u001b[39m         response = raw_response.parse()\n\u001b[32m   1329\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1330\u001b[39m         \u001b[43m_handle_openai_bad_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_responses_api(payload):\n\u001b[32m   1332\u001b[39m     original_schema_obj = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:467\u001b[39m, in \u001b[36m_handle_openai_bad_request\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    459\u001b[39m     message = (\n\u001b[32m    460\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInvalid schema for OpenAI\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms structured output feature, which is the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    461\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdefault method for `with_structured_output` as of langchain-openai==0.3. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://platform.openai.com/docs/guides/structured-outputs#supported-schemas\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    465\u001b[39m     )\n\u001b[32m    466\u001b[39m     warnings.warn(message)\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1324\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1321\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1322\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1323\u001b[39m     raw_response = (\n\u001b[32m-> \u001b[39m\u001b[32m1324\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1327\u001b[39m     )\n\u001b[32m   1328\u001b[39m     response = raw_response.parse()\n\u001b[32m   1329\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:184\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    179\u001b[39m         response_format=response_format,\n\u001b[32m    180\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    181\u001b[39m         input_tools=chat_completion_tools,\n\u001b[32m    182\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/python_3.11_udacity/lib/python3.11/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'QueryAttributeOutput': In context=('properties', 'document', 'properties', 'metadata'), 'additionalProperties' is required to be supplied and to be false.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"
     ]
    }
   ],
   "source": [
    "query = \"Hi, I have a question regarding the billing for the events I attended last month. There seems to be a discrepancy in the charges, and I would like to understand the breakdown of the costs. Could you please provide a detailed billing statement? Thank you.\"\n",
    "\n",
    "# Evaluate Retrival Score, Intent, Sentiment of the Query\n",
    "prompt_template = \"\"\"\n",
    "    You are a IT ticket evaluation agent, given the user query:\n",
    "    {query}\n",
    "\n",
    "    Use `knowledge_retrival` to extract \"retrival\" attribute from the ChromaDB knowledge database\n",
    "    \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template = prompt_template,\n",
    "    input_variables = [\"query\"],\n",
    "    ).invoke({\"query\": query})\n",
    "\n",
    "response = llm_initial_evaluator.with_structured_output(QueryAttributeOutput).invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eeebf3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryAttributeOutput(intent='refund_high', sentiment=0.5, confidencet=0.85)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1284ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3.11_udacity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
