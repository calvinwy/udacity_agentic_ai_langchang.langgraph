{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dad49ff",
   "metadata": {},
   "source": [
    "# Agentic AI Engineer with LangChain and LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc3f9d",
   "metadata": {},
   "source": [
    "## Project 1: Report-Building Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285aa8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from print_color import print\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "from src.assistant import DocumentAssistant\n",
    "\n",
    "from typing import TypedDict, List, Optional, Literal, Dict, Any, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c45714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Helper Functions\n",
    "\n",
    "def print_header():\n",
    "    \"\"\"Print a nice header\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"DocDacity Intelligent Document Assistant\", color='blue')\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "\n",
    "def print_help():\n",
    "    \"\"\"Print help information\"\"\"\n",
    "    print(\"\\nAVAILABLE COMMANDS:\", color='blue')\n",
    "    print(\"  /help     - Show this help message\")\n",
    "    print(\"  /docs     - List available documents\")\n",
    "    print(\"  /quit     - Exit the assistant\")\n",
    "    print(\"\\nExample queries:\")\n",
    "    print(\"  - What's the total amount in invoice INV-001?\")\n",
    "    print(\"  - Summarize all contracts\")\n",
    "    print(\"  - Calculate the sum of all invoice totals\")\n",
    "    print(\"  - Find documents with amounts over $50,000\")\n",
    "    print()\n",
    "\n",
    "\n",
    "def list_documents(assistant: DocumentAssistant):\n",
    "    \"\"\"List all available documents\"\"\"\n",
    "    print(\"\\nAVAILABLE DOCUMENTS:\", color='blue')\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for doc_id, doc in assistant.retriever.documents.items():\n",
    "        print(f\"ID: {doc_id}\")\n",
    "        print(f\"Title: {doc.title}\")\n",
    "        print(f\"Type: {doc.doc_type}\")\n",
    "        if 'total' in doc.metadata:\n",
    "            print(f\"Total: ${doc.metadata['total']:,.2f}\")\n",
    "        elif 'amount' in doc.metadata:\n",
    "            print(f\"Amount: ${doc.metadata['amount']:,.2f}\")\n",
    "        elif 'value' in doc.metadata:\n",
    "            print(f\"Value: ${doc.metadata['value']:,.2f}\")\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d52a80",
   "metadata": {},
   "source": [
    "### Task 1.1: AnswerResponse Schema\n",
    "Create a Pydantic model for structured Q&A responses with the following fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f30673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerResponse(BaseModel):\n",
    "    \"\"\"Pydantic model to ensure consistent formatting of answers and tracks which documents were referenced\"\"\"\n",
    "    question: Annotated[str, Field(description=\"The original user question\")]\n",
    "    answer: Annotated[str, Field(description=\"The generated answer\")]\n",
    "    sources: Annotated[List[str], Field(description=\"List of source document IDs used\")]\n",
    "    confidence: Annotated[float, Field(default=None, ge=0.0, le=1.0, description=\"Confidence score between 0 and 1\")]\n",
    "    timestamp: Annotated[datetime, Field(description=\"When the response was generated\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b770ad4b",
   "metadata": {},
   "source": [
    "## Task 1.2: UserIntent Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca07094",
   "metadata": {},
   "source": [
    "Create a Pydantic model for intent classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc884713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserIntent(BaseModel):\n",
    "    \"\"\"This schema helps the system understand what type of request the user is making and route it to the appropriate agent.\"\"\"\n",
    "    intent_type: Annotated[Literal['qa', 'summarization', 'calculation', 'unknown'], Field(description=\"The classified intent\")]\n",
    "    confidence: Annotated[float, Field(default=None, ge=0.0, le=1.0, description=\"Confidence in classification\")]\n",
    "    reasoning: Annotated[str, Field(description=\"Explanation for the classification\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca1cc7",
   "metadata": {},
   "source": [
    "# Task 2.2: Intent Classification Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269af1bb",
   "metadata": {},
   "source": [
    "Implement the `classify_intent` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\")\n",
    "TEMPERATURE = os.getenv(\"TEMPERATURE\")\n",
    "llm_base_url = \"https://openai.vocareum.com/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_intent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    The `classify_intent` function is the first node in the graph. It just purpose to query the LLM, \n",
    "    by providing both the user's input and message history (if any exists) and instruct the LLM to \n",
    "    classify the intent so that graph can direct the request to the appropriate node. Some of the code\n",
    "    for this function is already provided\n",
    "    \"\"\"\n",
    "    # Configure the `llm` to use structured output\n",
    "    llm = ChatOpenAI(\n",
    "                model=MODEL_NAME,\n",
    "                temperature=TEMPERATURE,\n",
    "                api_key=OPENAI_API_KEY,\n",
    "            )\n",
    "    llm.with_structured_output(UserIntent)\n",
    "\n",
    "    user_input = state[\"user_input\"]\n",
    "    conversation_history = state[\"messages\"]\n",
    "    prompt_template = get_intent_classification_prompt()\n",
    "    intent = llm.invoke(prompt_template.format(user_input=user_input, conversation_history=conversation_history))\n",
    "\n",
    "    if intent[\"intent_type\"] == \"qa\":\n",
    "        next_step = \"qa_agent\"\n",
    "    elif intent[\"intent_type\"] == \"summarization\":\n",
    "        next_step = \"summarization_agent\"\n",
    "    elif intent[\"intent_type\"] == \"calculation\":\n",
    "        next_step = \"calculation_agent\"\n",
    "    else:\n",
    "        next_step = \"qa_agent\"\n",
    "    \n",
    "    state[\"action_taken\"] = [\"classify_intent\"]\n",
    "    state[\"intent\"] = intent[\"intent_type\"]\n",
    "    state[\"next_step\"] = next_step\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main interactive loop\"\"\"\n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "\n",
    "    # Get API key\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"Error: OPENAI_API_KEY not found in environment variables\")\n",
    "        print(\"Please create a .env file with your OpenAI API key\")\n",
    "        return\n",
    "\n",
    "    # Print header\n",
    "    print_header()\n",
    "\n",
    "    # Create assistant\n",
    "    print(\" INITIALIZING ASSISTANT...\", color='green')\n",
    "    assistant = DocumentAssistant(\n",
    "        openai_api_key=api_key,\n",
    "        model_name=\"gpt-4o\",\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    # Start session\n",
    "    user_id = input(\"Enter your user ID (or press Enter for 'demo_user'): \").strip() or \"demo_user\"\n",
    "    session_id = assistant.start_session(user_id)\n",
    "    print(f\"Session started: {session_id}\")\n",
    "\n",
    "    # Show help\n",
    "    print_help()\n",
    "\n",
    "    # Main interaction loop\n",
    "    while True:\n",
    "        try:\n",
    "            # Get user input\n",
    "            user_input = input(\"\\nEnter Message: \").strip()\n",
    "\n",
    "            if not user_input:\n",
    "                continue\n",
    "\n",
    "            # Handle commands\n",
    "            if user_input.lower() == \"/quit\":\n",
    "                print(\"\\nGoodbye!\", color='blue')\n",
    "                break\n",
    "            elif user_input.lower() == \"/help\":\n",
    "                print_help()\n",
    "                continue\n",
    "            elif user_input.lower() == \"/docs\":\n",
    "                list_documents(assistant)\n",
    "                continue\n",
    "\n",
    "            # Process the message\n",
    "            print(\"\\nProcessing...\", color='yellow')\n",
    "            result = assistant.process_message(user_input)\n",
    "\n",
    "            if result[\"success\"]:\n",
    "                print(\"\\nðŸ¤– Assistant:\", end=\" \")\n",
    "\n",
    "                if result.get(\"response\"):\n",
    "                    print(result[\"response\"])\n",
    "                if result.get(\"intent\"):\n",
    "                    intent = result[\"intent\"]\n",
    "                    print(f\"\\nINTENT: {intent['intent_type']}\", color='green')\n",
    "                if result.get(\"active_documents\"):\n",
    "                    print(f\"\\nSOURCES: {', '.join(result['active_documents'])}\", color='blue')\n",
    "                if result.get(\"tools_used\"):\n",
    "                    print(f\"\\nTOOLS USED: {', '.join(result['tools_used'])}\", color='magenta')\n",
    "                if result.get(\"summary\"):\n",
    "                    print(f\"\\nCONVERSATION SUMMARY: {result['summary']}\", color='cyan')\n",
    "\n",
    "\n",
    "            else:\n",
    "                print(f\"\\nError: {result.get('error', 'Unknown error')}\", color='red')\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nGoodbye!\", color='blue')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\nUnexpected error: {str(e)}\", color='red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3.13.0_udacity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
